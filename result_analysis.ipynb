{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2731bef-0e5b-484b-b1db-59055bdcd871",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4460f04-f882-470c-b352-a3b3617dc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from k_popular_words import KMostPopularWords\n",
    "from single_task import KMostSingle\n",
    "from utils import ExperimentRunner\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61e4d3d0-2c85-4532-853c-ed462575f472",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"data/data_300MB.txt\", \"data/data_2.5GB.txt\", \"data/data_16GB.txt\"]\n",
    "experiment_runner = ExperimentRunner()\n",
    "\n",
    "k = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c5bb11-480c-41b3-8a1a-69df70e8351f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ee435-3a90-41e9-a797-81d43065902b",
   "metadata": {},
   "source": [
    "# Case 1: \n",
    "- Run as single task (without multi-thread and chunking)\n",
    "- Sorting Algorithm: python sort (Tim Sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09852eef-266a-4414-a151-14732988bf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: Baselinedata/data_300MB.txt\n",
      "Wall Time: 32.92 seconds\n",
      "CPU Time: 32.83 seconds\n",
      "Peak Memory Usage: 4375.38 MB\n",
      "[('european', 318532), ('mr', 210638), ('would', 181905), ('also', 180117), ('commission', 172768), ('must', 156850), ('president', 152132), ('union', 130292), ('states', 129472), ('member', 126221)]\n",
      "Running experiment: Baselinedata/data_2.5GB.txt\n",
      "Running experiment: Baselinedata/data_16GB.txt\n"
     ]
    }
   ],
   "source": [
    "for file_path in files:\n",
    "    try: \n",
    "        k_most = KMostPopularWords(file_path)\n",
    "        baseline_result = experiment_runner.run_experiment(\"Baseline\"+file_path, k_most.get_top_k_words_baseline, k)\n",
    "        print(baseline_result)\n",
    "        result.append([\"1\", file_path, experiment_runner.wall_time, experiment_runner.cpu_time, experiment_runner.peak_memory_usage/ 1024 / 1024])\n",
    "    except ValueError:\n",
    "        result.append([\"1\", file_path, None, None, None])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7393e9-9eea-4adf-8f0d-cf87c7cb7be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  'data/data_300MB.txt',\n",
       "  32.917779207229614,\n",
       "  32.82740000000001,\n",
       "  4375.37620639801],\n",
       " ['1', 'data/data_2.5GB.txt', None, None, None],\n",
       " ['1', 'data/data_16GB.txt', None, None, None]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafe121d-632d-4f66-b046-70e3de63bb0f",
   "metadata": {},
   "source": [
    "# Case 2: \n",
    "- Run as single task (without multi-thread and chunking\n",
    "- Sorting Algorithm: python heapq nlargest (Heap Sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a506ae4-1cfd-4014-983c-d67d50e4a6ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: Baselinedata/data_300MB.txt\n",
      "Wall Time: 32.70 seconds\n",
      "CPU Time: 32.63 seconds\n",
      "Peak Memory Usage: 4375.47 MB\n",
      "[('european', 318532), ('mr', 210638), ('would', 181905), ('also', 180117), ('commission', 172768), ('must', 156850), ('president', 152132), ('union', 130292), ('states', 129472), ('member', 126221)]\n",
      "Running experiment: Baselinedata/data_2.5GB.txt\n",
      "Running experiment: Baselinedata/data_16GB.txt\n"
     ]
    }
   ],
   "source": [
    "for file_path in files:\n",
    "    try: \n",
    "        k_most = KMostPopularWords(file_path, \"heap_sort\")\n",
    "        baseline_result = experiment_runner.run_experiment(\"Baseline\"+file_path, k_most.get_top_k_words_baseline, k)\n",
    "        print(baseline_result)\n",
    "        result.append([\"2\", file_path, experiment_runner.wall_time, experiment_runner.cpu_time, experiment_runner.peak_memory_usage/ 1024 / 1024])\n",
    "    except ValueError:\n",
    "        result.append([\"2\", file_path, None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2faab35-56fd-41ed-a058-c262a851afb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1',\n",
       "  'data/data_300MB.txt',\n",
       "  32.917779207229614,\n",
       "  32.82740000000001,\n",
       "  4375.37620639801],\n",
       " ['1', 'data/data_2.5GB.txt', None, None, None],\n",
       " ['1', 'data/data_16GB.txt', None, None, None],\n",
       " ['2',\n",
       "  'data/data_300MB.txt',\n",
       "  32.70103096961975,\n",
       "  32.62513099999995,\n",
       "  4375.474266052246],\n",
       " ['2', 'data/data_2.5GB.txt', None, None, None],\n",
       " ['2', 'data/data_16GB.txt', None, None, None]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(result).to_csv('result.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b789737-cd31-4994-a697-5b6e5535ef92",
   "metadata": {},
   "source": [
    "# Case 3:\n",
    "- Run as multi-tasks (with chunking)\n",
    "- Sorting Algorithm python sort (Tim Sort)\n",
    "- Different chunk sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cc3a366-7fae-48d4-8490-c4b39abb1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 1\n",
    "chunk_sizes = [400*1024*1024, 200*1024*1024, 100*1024*1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6ec5f0-7df4-4fa2-8ab9-8bc17ec175c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running experiment: Chunking-Timdata/data_300MB.txt\n",
      "Wall Time: 33.72 seconds\n",
      "CPU Time: 33.61 seconds\n",
      "Peak Memory Usage: 5021.16 MB\n",
      "[('european', 318532), ('mr', 210638), ('would', 181905), ('also', 180117), ('commission', 172768), ('must', 156850), ('president', 152132), ('union', 130292), ('states', 129472), ('member', 126221)]\n",
      "Running experiment: Chunking-Timdata/data_2.5GB.txt\n",
      "Wall Time: 307.15 seconds\n",
      "CPU Time: 296.66 seconds\n",
      "Peak Memory Usage: 6635.57 MB\n",
      "[('said', 2616235), ('one', 949399), ('would', 917205), ('new', 852788), ('also', 727930), ('last', 700206), ('people', 688742), ('mr', 659104), ('us', 643771), ('de', 643048)]\n",
      "Running experiment: Chunking-Timdata/data_16GB.txt\n",
      "Wall Time: 2368.40 seconds\n",
      "CPU Time: 2004.32 seconds\n",
      "Peak Memory Usage: 11324.80 MB\n",
      "[('said', 16980655), ('would', 5822354), ('one', 5794014), ('new', 5609010), ('also', 4616671), ('us', 4496155), ('people', 4255373), ('last', 4089050), ('two', 3956855), ('first', 3832029)]\n",
      "Running experiment: Chunking-Timdata/data_300MB.txt\n",
      "Wall Time: 32.40 seconds\n",
      "CPU Time: 32.41 seconds\n",
      "Peak Memory Usage: 3228.59 MB\n",
      "[('european', 318532), ('mr', 210638), ('would', 181905), ('also', 180117), ('commission', 172768), ('must', 156850), ('president', 152132), ('union', 130292), ('states', 129472), ('member', 126221)]\n",
      "Running experiment: Chunking-Timdata/data_2.5GB.txt\n",
      "Wall Time: 280.11 seconds\n",
      "CPU Time: 279.69 seconds\n",
      "Peak Memory Usage: 3917.12 MB\n",
      "[('said', 2616235), ('one', 949399), ('would', 917205), ('new', 852788), ('also', 727930), ('last', 700206), ('people', 688742), ('mr', 659104), ('us', 643771), ('de', 643048)]\n",
      "Running experiment: Chunking-Timdata/data_16GB.txt\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    chunk_size = chunk_sizes[i]\n",
    "    for file_path in files:\n",
    "        try: \n",
    "            k_most = KMostPopularWords(file_path)\n",
    "            baseline_result = experiment_runner.run_experiment(\"Chunking-Tim\" + file_path, k_most.get_top_k_words_chunk, k, chunk_size)\n",
    "            print(baseline_result)\n",
    "            result.append([\"3-\" + str(i), file_path, experiment_runner.wall_time, experiment_runner.cpu_time, experiment_runner.peak_memory_usage/ 1024 / 1024])\n",
    "        except ValueError:\n",
    "            result.append([\"3-\" + str(i), file_path, None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afbe7a-57c7-47e7-afee-6a6e988ec763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv('result.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2720499d-4fc3-447e-99ae-f00cf69d1f8d",
   "metadata": {},
   "source": [
    "# Case 4\n",
    "- Run as multi-tasks (witt chunking)\n",
    "- Sorting Algorithm: python heapq nlargest (Heap Sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0a8787-708a-4774-9469-f8e431812b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 200*1024*1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ed3ec-7dd9-45e3-a2bd-dd4ee5260a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in files:\n",
    "    try: \n",
    "        k_most = KMostPopularWords(file_path, \"heap_sort\")\n",
    "        baseline_result = experiment_runner.run_experiment(\"Chunking-heap\" + file_path, k_most.get_top_k_words_chunk, k, chunk_size)\n",
    "        print(baseline_result)\n",
    "        result.append([\"4\", file_path, experiment_runner.wall_time, experiment_runner.cpu_time, experiment_runner.peak_memory_usage/ 1024 / 1024])\n",
    "    except ValueError:\n",
    "        result.append([\"4\", file_path, None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d02bf37-6d41-448b-b7d5-021d89b30dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv('result.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12d4efb-9f83-4d65-b3d1-64dc06a4a7df",
   "metadata": {},
   "source": [
    "# Case 5\n",
    "- Run as multi-tasks (with multi-threads and chunking)\n",
    "- Sorting Algorithm: python sort (Tim Sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ff60fa-b34d-472a-8a0f-4e2b1fece59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 200*1024*1024\n",
    "num_thread = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691ceb9a-1c84-47a3-a544-11d4f3c4ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in files:\n",
    "    try: \n",
    "        k_most = KMostPopularWords(file_path)\n",
    "        baseline_result = experiment_runner.run_experiment(\"multi-thread\" + file_path, k_most.get_top_k_words_chunk_mt, k, num_thread, chunk_size)\n",
    "        print(baseline_result)\n",
    "        result.append([\"5\", file_path, experiment_runner.wall_time, experiment_runner.cpu_time, experiment_runner.peak_memory_usage/ 1024 / 1024])\n",
    "    except ValueError:\n",
    "        result.append([\"5\", file_path, None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d00f962-bd2f-49c4-b851-c98a4ad14192",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv('result.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacfdb4-7ecd-4f1b-b4d1-2eccff0458d9",
   "metadata": {},
   "source": [
    "# Case 6\n",
    "- Run as multi-tasks (with multi-process and chunking)\n",
    "- Sorting Algorithm: python sort (Tim Sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc113585-d274-4562-b138-32a96dc5fc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 200*1024*1024\n",
    "num_process = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9f6bb-6b39-47fb-b34b-b625bd16b2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_path in files:\n",
    "    try: \n",
    "        k_most = KMostPopularWords(file_path)\n",
    "        baseline_result = experiment_runner.run_experiment(\"multi-thread\" + file_path, k_most.get_top_k_words_chunk_mp, k, num_process, chunk_size)\n",
    "        print(baseline_result)\n",
    "        result.append([\"6\", file_path, experiment_runner.wall_time, experiment_runner.cpu_time, experiment_runner.peak_memory_usage/ 1024 / 1024])\n",
    "    except ValueError:\n",
    "        result.append([\"6\", file_path, None, None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0745b8e-aa57-4d78-b294-e1f88b8fa11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(result).to_csv('result.csv')\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa9d644-f2b1-413c-82a0-7da471bc0220",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa10620-f02a-460f-881f-750473202ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a855ee3-37b6-44b4-9196-a90f8bc91e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log Y axis\n",
    "def result_plot(df, title, y_title):\n",
    "    x = np.log(df['DataSize'])\n",
    "    plt.plot(x, np.log(df['Case1']), marker='o', label='Case 1')\n",
    "    plt.plot(x, np.log(df['Case2']), marker='o', label='Case 2')\n",
    "    plt.plot(x, np.log(df['Case3_1']), marker='o', label='Case 3')\n",
    "    \n",
    "    plt.title(title + ' vs Data Size for different algorithms')\n",
    "    plt.xlabel('Log Data Size in MB')\n",
    "    plt.ylabel(y_title)\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71f0196-7512-41f8-98f4-a8444f450b99",
   "metadata": {},
   "source": [
    "# without log Y axis\n",
    "def result_plot(df, title, y_title):\n",
    "    x = np.log(df['DataSize'])\n",
    "    plt.plot(x, df['Case1'], marker='o', label='Case 1')\n",
    "    plt.plot(x, df['Case2'], marker='o', label='Case 2')\n",
    "    plt.plot(x, df['Case3'], marker='o', label='Case 3')\n",
    "    \n",
    "    plt.title(title + ' vs Data Size for different algorithms')\n",
    "    plt.xlabel('Log Data Size in MB')\n",
    "    plt.ylabel(y_title)\n",
    "    plt.legend()\n",
    "\n",
    "    # Display the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2aea2c-065f-4531-9a0a-db88f2e4265f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result3_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928c449a-107a-492e-a734-24550e54ddea",
   "metadata": {},
   "source": [
    "## Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55265156-f300-4a89-80b4-efb5a00a5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "speed = {'data/data_300MB.txt': [300],\n",
    " 'data/data_2.5GB.txt': [2.5*1024]\n",
    " # 'data/data_16GB.txt': [16*1024]\n",
    "        }\n",
    "results = [result1, result2, result3_1]\n",
    "for result in results:\n",
    "    for key, value in result.items():\n",
    "        speed.setdefault(key, []).append(value[0])\n",
    "df_speed = pd.DataFrame(speed.values(), columns = ['DataSize', 'Case1', 'Case2', 'Case3_1'])\n",
    "df_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc5d28-5da4-44a2-95b5-9b5d427f77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_plot(df_speed, 'Runtime', 'Log Runtime in Second')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a422ee-f29b-4e6a-93ef-e1df0ff42029",
   "metadata": {},
   "source": [
    "## CPU utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640314b5-e0bc-4383-9950-04faae2260aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = {'data/data_300MB.txt': [300],\n",
    " 'data/data_2.5GB.txt': [2.5*1024]\n",
    " # 'data/data_16GB.txt': [16*1024]\n",
    "      }\n",
    "for result in results:\n",
    "    for key, value in result.items():\n",
    "        cpu.setdefault(key, []).append(value[2])\n",
    "df_cpu = pd.DataFrame(cpu.values(), columns = ['DataSize', 'Case1', 'Case2', 'Case3_1'])\n",
    "df_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d405b19-acaf-4e72-b739-ea802f2aef95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06b69331-834e-479b-a0cf-a87a26706f3d",
   "metadata": {},
   "source": [
    "## Ram Utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977469e5-b56b-492c-aa38-4422e498faa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ram = {'data/data_300MB.txt': [300],\n",
    " 'data/data_2.5GB.txt': [2.5*1024],\n",
    " 'data/data_16GB.txt': [16*1024]}\n",
    "for result in results:\n",
    "    for key, value in result.items():\n",
    "        ram.setdefault(key, []).append(value[2])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8adf5bb-a9e9-4b6f-905e-27256d6c6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ram = pd.DataFrame(ram.values(), columns = ['DataSize', 'Case1', 'Case2', 'Case3_1', 'Case3_2', 'Case4'])\n",
    "df_ram.to_csv('ram.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d83842-737f-4e59-92b3-6a49f9c3ab20",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_plot(df_ram, 'Ram Usage', 'Log Ram Usage in MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26e6230-bc6c-45cf-b721-4defa757ba34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc9413-d5be-410f-b60a-a88f9af8d8d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
